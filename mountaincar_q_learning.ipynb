{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually updating the Q value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T15:00:12.473386Z",
     "start_time": "2019-06-06T15:00:12.469511Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T15:00:12.791737Z",
     "start_time": "2019-06-06T15:00:12.728921Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")  # a very simple application\n",
    "done = False\n",
    "\n",
    "# Resets the state of the environment and returns an initial observation.\n",
    "env.reset()  # 2 observables - position and velocity\n",
    "\n",
    "# number of allowed actions  - 3: left push, no movement, right push\n",
    "# print(env.action_space.n)\n",
    "\n",
    "# there are only two observables - position and velocity\n",
    "# print(env.observation_space.high)  # the high values of the observations\n",
    "# print(env.observation_space.low)  # the low values\n",
    "\n",
    "# the range of values for observation 1 is 0.6 to -1.2\n",
    "# and similarly for observation 2 its 0.07 to -0.07\n",
    "# we can segregate the values in 20 chunks (can be any value)\n",
    "\n",
    "DISCRETE_OBSERVATION_SPACE_SIZE = [\n",
    "    20] * len(env.observation_space.high)  # will give out 20*20 list\n",
    "\n",
    "# see how big is the range for each of the 20 different buckets\n",
    "discrete_os_win_size = (env.observation_space.high -\n",
    "                        env.observation_space.low) / DISCRETE_OBSERVATION_SPACE_SIZE\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.95  # how important we find the new future actions are ; future reward over current reward\n",
    "EPISODES = 20000\n",
    "render = False\n",
    "\n",
    "# even though the solution might have been found, we still wish to look for other solutions\n",
    "epsilon = 0.5  # 0-1 ; higher it is, more likely for it to perform something random action\n",
    "START_EPSILON_DECAYING = 1\n",
    "# python2 style division - gives only int values\n",
    "END_EPSILON_DECAYING = EPISODES // 2\n",
    "epsilon_decay_value = epsilon / (END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
    "\n",
    "# Q learning\n",
    "# so we will have now a table such that each row will have 400 (20*20) rows for the possible state the agent can be in\n",
    "# and 3 columns for the 3 possible actions\n",
    "# the agent will see which state it is in and take the action corresponding to the largest Q value\n",
    "\n",
    "# Create a randomised q_table and agent will update it after exploring the environment\n",
    "q_table = np.random.uniform(\n",
    "    low=-2, high=0, size=(DISCRETE_OBSERVATION_SPACE_SIZE + [env.action_space.n]))\n",
    "\n",
    "# how to set low and high limits of rewards ? - if you see the rewards printed in below cell, they are mostly -1 and\n",
    "# might be something +ve only when you reach goal. Needs tweaking and playing around\n",
    "# print(q_table.shape)\n",
    "\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int))  # return as tuple\n",
    "\n",
    "\n",
    "# # get Q value of this discrete state\n",
    "# print(q_table[discrete_state])\n",
    "\n",
    "# # print action corresponding to the max Q value\n",
    "# print(np.argmax(q_table[discrete_state]))\n",
    "\n",
    "# # print the max q-value for that state\n",
    "# print(np.max(q_table[discrete_state]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T15:00:48.592510Z",
     "start_time": "2019-06-06T15:00:13.200633Z"
    }
   },
   "outputs": [],
   "source": [
    "for ep in range(EPISODES):\n",
    "    done = False\n",
    "    discrete_state = get_discrete_state(env.reset())  # initial discrete state\n",
    "\n",
    "    if ep % 500 == 0:\n",
    "        render = True\n",
    "    else:\n",
    "        render = False\n",
    "        env.close()\n",
    "\n",
    "\n",
    "    while not done:  # goal reached means reward = 0\n",
    "\n",
    "        if np.random.random() > epsilon:\n",
    "            # in this environment, 0 means push the car left, 1 means to do nothing, 2 means to push it right\n",
    "            action = np.argmax(q_table[discrete_state])\n",
    "        else:\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "\n",
    "        # Run one timestep of the environment's dynamics;  returns a tuple (observation, reward, done, info).\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "        if not done:\n",
    "            # max q value for the next state calculated above\n",
    "            max_future_q = np.max(q_table[new_discrete_state])\n",
    "\n",
    "            # q value for the current action and state\n",
    "            current_q = q_table[discrete_state + (action, )]\n",
    "\n",
    "            new_q = (1 - LEARNING_RATE) * current_q + \\\n",
    "                LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "\n",
    "            # based on the new q, we update the current Q value\n",
    "            q_table[discrete_state + (action, )] = new_q\n",
    "\n",
    "        # goal reached; reward = 0 and no more negative\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            print((\"Goal reached at {} episode\".format(ep)))\n",
    "            # its like a snowbal effect, once the goal is reached - it will most likely reach again soon enough\n",
    "            q_table[discrete_state + (action, )] = 0\n",
    "\n",
    "        discrete_state = new_discrete_state\n",
    "\n",
    "    if END_EPSILON_DECAYING >= ep >= START_EPSILON_DECAYING:\n",
    "        epsilon -= epsilon_decay_value\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T08:33:14.619136Z",
     "start_time": "2019-06-02T08:33:14.609466Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural network"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The portion inside the brackets becomes the loss function for our neural network where Q(st,at) is the output of our network and rt + γ max Q(st+1,at+1) is the target Q value as well as the label for our neural net turning the problem into a supervised learning problem solvable using gradient descent where α is our learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T11:43:10.047281Z",
     "start_time": "2019-06-03T11:43:06.455139Z"
    }
   },
   "source": [
    "Using a single layer and 200 hidden unit network to learn the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T14:37:10.166445Z",
     "start_time": "2019-06-06T14:37:10.162728Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T11:53:05.032533Z",
     "start_time": "2019-06-03T11:53:05.025838Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T14:37:11.159505Z",
     "start_time": "2019-06-06T14:37:11.149950Z"
    }
   },
   "outputs": [],
   "source": [
    "class policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(policy, self).__init__()\n",
    "        self.state_space = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "        self.hidden = 200 # num of hidden units \n",
    "        self.l1 = nn.Linear(self.state_space, self.hidden, bias=False) # input layer to hidden layer \n",
    "        self.l2 = nn.Linear(self.hidden, self.action_space, bias=False)  # hidden layer to output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        model = nn.Sequential(self.l1, self.l2)  # creating a model with the given layers\n",
    "        return model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T14:48:16.840784Z",
     "start_time": "2019-06-06T14:44:10.092241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "steps = 2000\n",
    "epsilon = 0.3\n",
    "gamma = 0.99\n",
    "loss_history = []\n",
    "reward_history = []\n",
    "episodes = 1000\n",
    "max_position = -0.4\n",
    "learning_rate = 0.03\n",
    "successes = 0\n",
    "position = []\n",
    "\n",
    "# Initialize Policy\n",
    "env = gym.make('MountainCar-v0')\n",
    "state = env.reset()\n",
    "pol = policy()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(pol.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T14:48:16.840784Z",
     "start_time": "2019-06-06T14:44:10.092241Z"
    }
   },
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "    episode_loss = 0\n",
    "    episode_reward = 0\n",
    "    state = env.reset()\n",
    "\n",
    "    for s in range(steps):\n",
    "        if episode % 200 == 0 and episode > 0:\n",
    "            env.render()\n",
    "        \n",
    "        # Get first action value function\n",
    "        Q = pol(Variable(torch.from_numpy(state).type(torch.FloatTensor)))\n",
    "        \n",
    "        # Choose epsilon-greedy action\n",
    "        if np.random.rand(1) < epsilon:\n",
    "            action = np.random.randint(0,3)\n",
    "        else:\n",
    "            _, action = torch.max(Q, -1)\n",
    "            action = action.item()\n",
    "        \n",
    "        # Step forward and receive next state and reward\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        new_Q = pol(Variable(torch.from_numpy(new_state).type(torch.FloatTensor)))\n",
    "        max_new_Q, _ = torch.max(new_Q, -1)\n",
    "        \n",
    "        # Create target Q value for training the policy\n",
    "        Q_target = Q.clone()\n",
    "        Q_target = Variable(Q_target.data)\n",
    "        Q_target[action] = reward + torch.mul(max_new_Q.detach(), gamma)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(Q, Q_target)\n",
    "        \n",
    "        # Update policy\n",
    "        pol.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record history\n",
    "        episode_loss += loss.item()\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # Keep track of max position\n",
    "        if new_state[0] > max_position:\n",
    "            max_position = new_state[0]\n",
    "        \n",
    "        if done:\n",
    "            if new_state[0] >= 0.5:\n",
    "                print(\"Success at episode \", ep)\n",
    "                epsilon *= .99                 # Adjust epsilon\n",
    "                scheduler.step()                # Adjust learning rate\n",
    "                successes += 1                # Record successful episode\n",
    "                \n",
    "            # Record history\n",
    "            loss_history.append(episode_loss)\n",
    "            reward_history.append(episode_reward)\n",
    "            weights = np.sum(np.abs(pol.l2.weight.data.numpy()))+np.sum(np.abs(pol.l1.weight.data.numpy()))\n",
    "            position.append(new_state[0])\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            state = new_state\n",
    "            \n",
    "print('successful episodes: {}'.format(successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
